---
layout: post
title:  "h2o와 nginx의 성능 비교"
date:   2015-05-06 01:00:00
categories: Qiita
---

# h2o와 nginx의 성능 비교

- - -

nginx 보다 빠르다고하는 h2o 이지만, 실제로 자신도 현지에서 벤치 마크를 취해 보았습니다. 환경은 다음과 같습니다.

- EC2의 c4.8xlarge 인스턴스
- gcc (GCC) 4.8.2 20140120 (Red Hat 4.8.2-16)
- Linux ip-172-31-13-40 3.14.35-28.38.amzn1.x86_64 # 1 SMP Wed Mar 11 - 22:50:37 UTC 2015 x86_64 x86_64 x86_64 GNU / Linux
- nginx-1.8.0
- h2o-1.2.1-alpha1
- wrk (벤치 마크)

#### 벤치 마크 명령

- - -

실행하는 벤치 마크 명령은 다음입니다. 또한 옵션은 최대한 Request / sec가 커지도록 조정하고 있습니다.

```
./wrk -c 100 -t 10 -d 10 http://127.0.0.1/
```

#### 서버가 반환 응답

- - -

서버가 반환하는 응답은 nginx에 포함 된 index.html 입니다. 크기는 612 바이트입니다.

```
$ cat /usr/local/nginx/html/index.html 
 <! DOCTYPE html> 
<html> 
<head> 
<title> Welcome to nginx! </ title> 
<style> 
    body  { 
        width :  35em ; 
        margin :  0  auto ; 
        font-family :  Tahoma ,  Verdana ,  Arial ,  sans-serif ; 
    } 
</ style> 
</ head> 
<body> 
<h1> Welcome to nginx! </ h1> 
<p> If you see this page, the nginx web server is successfully installed and
working. Further configuration is required. </ p>

<p> For online Documentation and support please refer to
 <a  href= "http://nginx.org/"> nginx.org </a> . <br/>
Commercial support is available at
<a  href= "http://nginx.com/"> nginx.com </a> . </ p>

<p> <em> Thank you for using nginx. </ em> </ p> 
</ body> 
</ html>
$
```

##### sysctl.conf

- - -

또한 미리 아래와 같은 매개 변수를 추가하여 커널 매개 변수를 조정 해 둡니다. (따로 필요 없어 살 수)

```
net.core.somaxconn = 32768
net.core.netdev_max_backlog = 32768
net.ipv4.tcp_max_syn_backlog = 32768
net.ipv4.tcp_tw_recycle = 1
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_fin_timeout = 10
net.core.rmem_max = 16777216
net.core.wmem_max = 16777216
net.ipv4.tcp_rmem = 4096 349520 16777216
net.ipv4.tcp_wmem = 4096 65536 16777216
net.ipv4.ip_local_port_range = 1024 65535
net.ipv4.tcp_timestamps = 0
```


##### h2o

---

에서는 우선 h2o 벤치 마크에서 시작합니다.


#### h2o.conf (초기 상태)

---

h2o 설정 파일 (초기 상태)을 이런 식으로 정의합니다.

```
listen :  80 
hosts : 
  "127.0.0.1:80" : 
    paths : 
      / : 
        file.dir :  / usr / local / nginx / html
```


#### 벤치 마크 (초기 상태)

---

```
Running 10s test @ http://127.0.0.1
  10 threads and 100 connections
  Thread Stats Avg Stdev Max + Stdev
    Latency 265.78us 760.09us 17.04ms 96.66 %
    Req / Sec 59.04k 7.09k 116.13k 71.93 %
  5880641 requests in 10.10s, 4.56GB read
Requests / sec : 582269.87
Transfer / sec : 462.01MB
```
58초

#### 스레드 수를 조정

---

h2o는 기본적으로 CPU 코어 수와 같은 수의 작업자 스레드를 시작합니다. 
이것은 이것대로 좋겠지 만, 이번처럼 로컬에서 벤치 마크를 실행하면 
CPU 코어 수와 같은 수의 작업자 스레드를 시작하게되면 벤치 마크 프로그램과 CPU를 잡고 버리기 때문에 작업자 스레드 수를 작게 해보십시오. (하는 김에 최대 연결 수도 올립니다)

```
num-threads :  16 
num-name-resolution-threads :  1 
max-connections :  10240
```

이제 다시 벤치 마크를 실행하면

```
Running 10s test @ http://127.0.0.1
  10 threads and 100 connections
  Thread Stats Avg Stdev Max + Stdev
    Latency 158.90us 302.95us 14.96ms 97.11 %
    Req / Sec 71.36k 10.12k 106.08k 70.63 %
  7153711 requests in 10.10s, 5.54GB read
Requests / sec : 708328.89
Transfer / sec : 562.03MB
```

초 70 만 요청을 넘었습니다. 또한 num-threads 는 더 이상 늘려도 wrk 와 CPU를 잡고 버리는 탓인지 성능이 올라가지 않았습니다.


최종 h2o.conf는 여기에있다.

```
num-threads :  16 
num-name-resolution-threads :  1 
max-connections :  10240 
listen :  80 
hosts : 
  "127.0.0.1:80" : 
    paths : 
      / : 
        file.dir :  / usr / local / nginx / html
```


#### nginx

---


이어 nginx입니다.

#### nginx.conf (초기 상태)

---

nginx.conf의 초기 상태는 다음입니다. nginx를 설치 한 직후 nginx.conf에서 오류 계의 설정과 댓글의 제거, 액세스 로그 오프 등을 실시하고 있습니다.

```
worker_processes   1 ;

events  { 
    worker_connections   1024 ; 
}

http  { 
    include        mime.types ; 
    default_type   Application / octet-stream ;

    access_log  OFF ;

    sendfile  on ;

    keepalive_timeout   65 ;

    server  { 
        listen        80 ; 
        server_name   localhost ; 
        location  /  { 
            루트    HTML ; 
            index   index.html  index.htm ; 
        } 
    } 
}
```

#### 벤치 마크 (초기 상태)

---

```
Running 10s test @ http://127.0.0.1/
  10 threads and 100 connections
  Thread Stats Avg Stdev Max + Stdev
    Latency 45.04ms 58.61ms 206.35ms 78.77 %
    Req / Sec 5.52k 2.77k 10.10k 62.83 %
  535382 requests in 10.02s, 433.46MB read
Requests / sec : 53433.93
Transfer / sec : 43.26MB
```
5 초

#### 작업자 프로세스 및 연결 수를 증가

---

nginx는 h2o와 달리 기본 작업자 수가 작기 때문에 이것을 조금 전의 h2o.conf과 같이 16합니다. (또한 최대 연결 수도 동일합니다)

```
worker_processes  16 ; 
events  { 
    worker_connection  10240 ; 
}
```

(추기 : h2o의 max-connectoins ≒ nginx의 worker_processes * worker_connections이므로 실제로는 차이가있을 수 있다는 의견을 받았으므로 만약을 위해 추가 시험을 시도했지만 연결 수는 바꿔도 점수는 거의 동일 했다. (h2o의 max-connections를 10240, nginx의 worker_connections 1024 or 640에 실시))
이제 벤치 마크를 실행 시키면,

```
Running 10s test @ http://127.0.0.1
  10 threads and 100 connections
  Thread Stats Avg Stdev Max + Stdev
    Latency 827.38us 2.79ms 64.81ms 94.35 %
    Req / Sec 62.79k 8.74k 77.95k 84.26 %
  6308521 requests in 10.10s, 4.99GB read
Requests / sec : 624638.51
Transfer / sec : 505.72MB
```
62 초 요청합니다. 단번에 성장했습니다.

#### open_file_cache에서 파일 정보를 캐시

---

nginx에 한 번 오픈 한 파일 기술자와 크기, 업데이트 시간, i-node 같은 정보를 캐시하는 open_file_cache 라는 지시문이 있습니다.

```
# max : 캐시의 최대 
# inactive : 권한이없는 캐시 만료 
open_file_cache  MAX = 100  inactive = 20s ;
```

이것을 설정하고 벤치 마크를 실행 시키면,

```
Running 10s test @ http://127.0.0.1
  10 threads and 100 connections
  Thread Stats Avg Stdev Max + Stdev
    Latency 761.52us 6.12ms 138.30ms 98.88 %
    Req / Sec 70.55k 8.20k 85.08k 87.69 %
  7073264 requests in 10.10s, 5.59GB read
Requests / sec : 700324.14
Transfer / sec : 567.00MB
```

h2o만큼의 수준까지 도달했습니다.


#### accept_mutex_delay

---

accept_mutex_delay 는 accept () 때의 mutex의 확보에 실패했을 때의 대기 시간을 조정하는 지시어입니다. 기본이라고 500ms에서 이것이라고 조금 크기 때문에 100ms합니다.


```
accept_mutex_delay  100ms ;
```

이제 벤치 마크를 실행 시키면,

```
Running 10s test @ http://127.0.0.1
  10 threads and 100 connections
  Thread Stats Avg Stdev Max + Stdev
    Latency 401.34us 2.83ms 85.56ms 98.64 %
    Req / Sec 72.03k 8.27k 105.77k 86.40 %
  7216133 requests in 10.10s, 5.71GB read
Requests / sec : 714511.56
Transfer / sec : 578.48MB
```

h2o을 넘었습니다.


#### tcp_nopush

---

tcp_nopush 는 nginx가 사용하는 TCP 소켓에 TCP_CORK (Linux) 또는 TCP_NOPSUH (BSD) 옵션을 설정하는 지시어입니다. 이를 사용하면 간단히 응답 헤더와 파일의 내용을 정리해 보내 게되므로 전송 패킷 수를 최소화 할 수 있습니다.

```
tcp_nopush  on ;
```

이제 벤치 마크를 실행 시키면,

```
Running 10s test @ http://127.0.0.1
  10 threads and 100 connections
  Thread Stats Avg Stdev Max + Stdev
    Latency 163.09us 0.99ms 36.45ms 99.12 %
    Req / Sec 82.93k 9.71k 110.85k 69.90 %
  8330029 requests in 10.10s, 6.59GB read
Requests / sec : 824799.77
Transfer / sec : 667.78MB
```

초 82 만 요청합니다. 대단하네요. 최종 nginx.conf는 다음입니다.

```
worker_processes  16 ;

events  { 
    worker_connections   10240 ; 
    accept_mutex_delay  100ms ; 
}

http  { 
    include        mime.types ; 
    default_type   Application / octet-stream ;

    access_log  OFF ;

    sendfile  on ; 
    open_file_cache  MAX = 100  inactive = 20s ; 
    tcp_nopush  on ;

    keepalive_timeout   65 ;

    server  { 
        listen        80 ; 
        server_name   localhost ; 
        location  /  { 
            루트    HTML ; 
            index   index.html  index.htm ; 
        } 
    } 
}
```

#### 정리

---

h2o와 nginx의 벤치 마크를 로컬에 취해 보았습니다. 실제로 해본 소감으로는

- h2o은 대부분 설정하지 않아도 꽤 성능이 나오게있는

- nginx도 튜닝에 따라 h2o에 필적하는 성능은 발행

같은 곳인가요? 한편 이번 nginx 측에서 설정 한 open_file_cache 과 tcp_nopush 상당의 기능은 아직 h2o에는 구현되어 있지 않습니다. 이 두 단지 초 20 만정도 다르기 때문에 h2o에서도이 구현되면 딱딱 튜닝 한 nginx보다 빨리 될 것입니다. open_file_cache 대해 진행중인 지점 이있는 것 같습니다.
그런데 tcp_nopush 은 본래 tcp_nodelay (nginx에서 기본적으로 사용)와 반대의 동작을 합니다만, nginx는이 두가지를 합쳐서 잘 작동하도록 구현되어있는 것 같습니다. ( NGINX OPTIMIZATION : UNDERSTANDING SENDFILE, TCP_NODELAY AND TCP_NOPUSH )
